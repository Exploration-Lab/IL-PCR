{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba4c54ec",
   "metadata": {},
   "source": [
    "### Make Event and  IOU filtered corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff51538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import os, sys\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "def convert_segment_dict_to_events_dataset(segment_dir, out_path):\n",
    "    if out_path[-1] != \"/\":\n",
    "        out_path = out_path + f'/'\n",
    "\n",
    "    assert(os.path.isdir(segment_dir))\n",
    "    for file in os.listdir(segment_dir):\n",
    "        file = segment_dir + f'/{file}'\n",
    "        if \"query\" in file :\n",
    "            query_events = file\n",
    "            with open(query_events, 'rb') as f:\n",
    "                query_events = pkl.load(f)\n",
    "                query_events = query_events['dict_query']\n",
    "\n",
    "        elif \"candidate\" in file :\n",
    "            candidate_events = file\n",
    "            with open(candidate_events, 'rb') as f:\n",
    "                candidate_events = pkl.load(f)\n",
    "                candidate_events = candidate_events['dict_candidate']\n",
    "\n",
    "    # with open(f'./temp.txt', 'w+') as f:\n",
    "    #     print(candidate_events, file = f)\n",
    "\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    os.makedirs(out_path + 'query/', exist_ok=True)\n",
    "    os.makedirs(out_path + 'candidate/', exist_ok=True)\n",
    "\n",
    "    for query_num in query_events.keys():\n",
    "        text = \" \".join(query_events[query_num])\n",
    "        temp_path = out_path + f'query/{query_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    for candidate_num in candidate_events.keys():\n",
    "        text = \" \".join(candidate_events[candidate_num])\n",
    "        temp_path = out_path + f'candidate/{candidate_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    return \n",
    "\n",
    "def convert_segment_dict_to_iouf_dataset(segment_dir, out_path):\n",
    "    if out_path[-1] != \"/\":\n",
    "        out_path = out_path + f'/'\n",
    "\n",
    "    assert(os.path.isdir(segment_dir))\n",
    "    for file in os.listdir(segment_dir):\n",
    "        file = segment_dir + f'/{file}'\n",
    "        if \"IOU\" not in file :\n",
    "            continue\n",
    "\n",
    "        with open(file, 'rb') as f: # single file contains query and candidate corpus\n",
    "            _ = pkl.load(f) \n",
    "        query_events = _['dict_query']\n",
    "        candidate_events = _['dict_candidate']\n",
    "\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    os.makedirs(out_path + 'query/', exist_ok=True)\n",
    "    os.makedirs(out_path + 'candidate/', exist_ok=True)\n",
    "\n",
    "    for query_num in query_events.keys():\n",
    "        text = \" \".join(query_events[query_num])\n",
    "        temp_path = out_path + f'query/{query_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    for candidate_num in candidate_events.keys():\n",
    "        text = \" \".join(candidate_events[candidate_num])\n",
    "        temp_path = out_path + f'candidate/{candidate_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    return \n",
    "\n",
    "# events for ILPCR dataset \n",
    "# standard corpus, with citations\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/test', './corpus/ik_test_events')\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/train', './corpus/ik_train_events')\n",
    "\n",
    "# without citations\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/test', './corpus/sentence_removed/ik_test_events')\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/train', './corpus/sentence_removed/ik_train_events')\n",
    "\n",
    "# # events for COLIEE2021 dataset\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/coliee21_processed/coliee21/test', './corpus/COLIEE2021_test_events')\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/coliee21_processed/coliee21/train', './corpus/COLIEE2021_train_events')\n",
    "\n",
    "# iouf corpus for ILPCR dataset\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/test', './corpus/ik_test_iouf')\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/train', './corpus/ik_train_iouf')\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/test', './corpus/sentence_removed/ik_test_iouf')\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/train', './corpus/sentence_removed/ik_train_iouf')\n",
    "\n",
    "# iouf corpus for COLIEE2021 dataset\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/coliee21_processed/coliee21/test', './corpus/COLIEE2021_test_iou_filtered/')\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/coliee21_processed/coliee21/train', './corpus/COLIEE2021_train_iou_filtered/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f295177",
   "metadata": {},
   "source": [
    "### Make atomic events corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0f9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_segment_dict_to_atomic_events_dataset(segment_dir, out_path):\n",
    "    if out_path[-1] != \"/\":\n",
    "        out_path = out_path + f'/'\n",
    "\n",
    "    assert(os.path.isdir(segment_dir))\n",
    "    for file in os.listdir(segment_dir):\n",
    "        file = segment_dir + f'/{file}'\n",
    "        if \"query\" in file :\n",
    "            query_events = file\n",
    "            with open(query_events, 'rb') as f:\n",
    "                query_events = pkl.load(f)\n",
    "                query_events = query_events['dict_query']\n",
    "\n",
    "        elif \"candidate\" in file :\n",
    "            candidate_events = file\n",
    "            with open(candidate_events, 'rb') as f:\n",
    "                candidate_events = pkl.load(f)\n",
    "                candidate_events = candidate_events['dict_candidate']\n",
    "\n",
    "    token_dict = {}\n",
    "    counter=0\n",
    "    for query in query_events:\n",
    "        for event in query_events[query]:\n",
    "            if event not in token_dict:\n",
    "                token_dict[event] = counter\n",
    "                counter+=1\n",
    "\n",
    "    for candidate in candidate_events:\n",
    "        for event in candidate_events[candidate]:\n",
    "            if event not in token_dict:\n",
    "                token_dict[event] = counter\n",
    "                counter+=1\n",
    "\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    os.makedirs(out_path + 'query/', exist_ok=True)\n",
    "    os.makedirs(out_path + 'candidate/', exist_ok=True)\n",
    "\n",
    "    for query_num in query_events.keys():\n",
    "        text = \". \".join([str(token_dict[i]) for i in query_events[query_num]])\n",
    "        temp_path = out_path + f'query/{query_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    for candidate_num in candidate_events.keys():\n",
    "        text = \". \".join([str(token_dict[i]) for i in candidate_events[candidate_num]])\n",
    "        temp_path = out_path + f'candidate/{candidate_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "    \n",
    "    return\n",
    "\n",
    "# Atomic event corpus for ILPCR\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/test', './corpus/ik_test_atomic')\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/train', './corpus/ik_train_atomic')\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/test', './corpus/sentence_removed/ik_test_atomic')\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/train', './corpus/sentence_removed/ik_train_atomic')\n",
    "\n",
    "# Atomic event corpus for COLIEE2021 dataset\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/coliee21_processed/coliee21/test', './corpus/COLIEE2021_test_atomic')\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/coliee21_processed/coliee21/train', './corpus/COLIEE2021_train_atomic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
