{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import pickle as pkl\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from tqdm import tqdm\n", "import os\n", "import json"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "load IOU_filtered_input_details.json"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with open(r\"./IOU_filtered_input_details.json\", 'rb') as f:\n", "    input_details = json.load(f)\n", "# load segment dictionary\n", "dataset = input_details['dataset']  # indiankanoon,COLIEE etc\n", "split_type = input_details['split_type']  # train,dev,test"]}, {"cell_type": "markdown", "metadata": {}, "source": ["load segment dictionary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["seg_data_dir_path = input_details['seg_data_dir_path']\n", "# load segment dictionary for cadidate\n", "seg_path_candi = seg_data_dir_path+\"/\"+dataset+\"/\"+split_type + \\\n", "    \"/segment_dictionary_\"+split_type+\"_\"+dataset+\"_candidate.sav\"\n", "with open(seg_path_candi, 'rb') as f:\n", "    candi_seg_dict = pkl.load(f)\n", "# load segment dictionary for query\n", "seg_path_query = seg_data_dir_path+\"/\"+dataset+\"/\"+split_type + \\\n", "    \"/segment_dictionary_\"+split_type+\"_\"+dataset+\"_query.sav\"\n", "with open(seg_path_query, 'rb') as f:\n", "    query_seg_dict = pkl.load(f)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["load event doc line text"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["event_doc_line_text_dir_path = input_details['event_doc_line_text_dir_path']\n", "# load event doc line text for cadidate\n", "event_doc_line_text_path_candi = event_doc_line_text_dir_path+\"/\"+dataset + \\\n", "    \"/\"+split_type + \"/event_doc_line_text_\"+split_type+\"_\"+dataset+\"_candidate.pkl\"\n", "with open(event_doc_line_text_path_candi, 'rb') as f:\n", "    candidate_event_doc_txt = pkl.load(f)\n", "# load event doc line text for query\n", "event_doc_line_text_path_query = event_doc_line_text_dir_path+\"/\"+dataset + \\\n", "    \"/\"+split_type + \"/event_doc_line_text_\"+split_type+\"_\"+dataset+\"_query.pkl\"\n", "with open(event_doc_line_text_path_query, 'rb') as f:\n", "    query_event_doc_txt = pkl.load(f)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Loaded seg_path_query:\", seg_path_query)\n", "print(\"Loaded seg_path_candi:\", seg_path_candi)\n", "print(\"Loaded event_doc_line_text_path_query:\", event_doc_line_text_path_query)\n", "print(\"Loaded event_doc_line_text_path_candi:\", event_doc_line_text_path_candi)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "sorted list of all queries and candidates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["all_queries = sorted(list(query_seg_dict['dict_query'].keys()))\n", "all_candidates = sorted(list(candi_seg_dict['dict_candidate'].keys()))\n", "print(len(all_queries))\n", "print(len(all_candidates))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "making matrix of all common events between queries and candidates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["qc_mat = list()\n", "for q in tqdm(all_queries,desc=\"Matrix Calculation:\"):\n", "    # print(q)\n", "    qc_events = list()\n", "    # q_events = {tuple(e) for e in query_seg_dict['dict_query'][q]}\n", "    q_events = set(query_seg_dict['dict_query'][q])\n", "    for c in all_candidates:\n", "        # print(c)\n", "        if q != c:\n", "            # c_events = {tuple(e) for e in candi_seg_dict['dict_candidate'][c]}\n", "            c_events = set(candi_seg_dict['dict_candidate'][c])\n", "            qc_events.append(q_events.intersection(c_events))\n", "        else:\n", "            # print(\"same\",q,c)\n", "            qc_events.append(set())\n", "        # break\n", "    qc_mat.append(qc_events)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "check length of qc_mat = number of queries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(len(qc_mat))\n", "# check length of all lists qc_mat = number of candidates\n", "ct = set()\n", "for ql in qc_mat:\n", "    ct.add(len(ql))\n", "print(ct)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "unique events in a query"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_events = {}\n", "for i in range(len(all_queries)):\n", "    q_id = all_queries[i]\n", "    # print(q_id)\n", "    qc_events = qc_mat[i]\n", "    qc_common = set().union(*qc_events)\n", "    query_events[q_id] = qc_common\n", "    # break\n", "# check length of query_events = number of queries\n", "print(len(query_events))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "unique events in a candidate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["candidate_events = {}\n", "for i in range(len(all_candidates)):\n", "    c_id = all_candidates[i]\n", "    # print(c_id)\n", "    cq_events = list()\n", "    for row in qc_mat:\n", "        cq_events.append(row[i])\n", "    cq_common = set().union(*cq_events)\n", "    candidate_events[c_id] = cq_common\n", "    # break"]}, {"cell_type": "markdown", "metadata": {}, "source": ["check length of candidate_events = number of candidates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(len(candidate_events))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "convert common query events into the source sentences"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_text = {}\n", "for q, eves in query_events.items():\n", "    q_txt = {}\n", "    for eve in list(eves):\n", "        if eve in query_event_doc_txt:\n", "            if q in query_event_doc_txt[eve]:\n", "                q_txt.update(query_event_doc_txt[eve][q])\n", "    q_lst = []\n", "    for key in sorted(list(q_txt.keys())):\n", "        # print(key,\"::\",q_txt[key])\n", "        q_lst.append(q_txt[key])\n", "    query_text[q] = q_lst\n", "    # break"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "convert common candidate events into the source sentences"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["candidate_text = {}\n", "for c, eves in candidate_events.items():\n", "    c_txt = {}\n", "    for eve in list(eves):\n", "        if eve in candidate_event_doc_txt:\n", "            if c in candidate_event_doc_txt[eve]:\n", "                c_txt.update(candidate_event_doc_txt[eve][c])\n", "    c_lst = []\n", "    for key in sorted(list(c_txt.keys())):\n", "        # print(key,\"::\",c_txt[key])\n", "        c_lst.append(c_txt[key])\n", "    candidate_text[c] = c_lst"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "save all text in dictionary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["event_text_dict = dict()\n", "event_text_dict['dict_query'] = query_text\n", "event_text_dict['dict_candidate'] = candidate_text"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "save file to location"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["output_path = input_details['output_dir']+\"/\"+dataset+\"/\"+split_type\n", "output_file_path = output_path+\"/IOU_filtered_text_dict_\"+dataset+\"_\"+split_type+\".sav\"\n", "os.makedirs(output_path, exist_ok=True)\n", "with open(output_file_path, 'wb') as f:\n", "    try:\n", "        pkl.dump(event_text_dict, f)\n", "    except:\n", "        print(\"Couldn't save\")\n", "    f.close()\n", "print(\"Saved IOU_filtered_text_dict_\"+dataset +\n", "      \"_\"+split_type+\".sav at:\", output_file_path)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}